{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e48212bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehul\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7b76892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.1.2+cpu\n",
      "Has torch.compiler? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehul\\AppData\\Roaming\\Python\\Python310\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\mehul\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ BERT model loaded!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"Has torch.compiler?\", hasattr(torch, \"compiler\"))\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "print(\"✅ BERT model loaded!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "807b716c",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.read_csv('news.tsv', sep='\\t', header=None,\n",
    "                      names=['news_id', 'category', 'subcategory', 'title', 'abstract', 'url', 'title_entities', 'abstract_entities'])\n",
    "\n",
    "news_df['content'] = news_df['title'].fillna('') + ' ' + news_df['abstract'].fillna('')\n",
    "news_df = news_df[['news_id', 'title', 'content']]\n",
    "\n",
    "behaviors_df = pd.read_csv('behaviors.tsv', sep='\\t', header=None,\n",
    "                           names=['impression_id', 'user_id', 'time', 'history', 'impressions'])\n",
    "\n",
    "behaviors_df = behaviors_df.dropna(subset=['history'])\n",
    "behaviors_df['clicked_news'] = behaviors_df['history'].apply(lambda x: x.strip().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e9b632c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_clicks = []\n",
    "for _, row in behaviors_df.iterrows():\n",
    "    for nid in row['clicked_news']:\n",
    "        user_clicks.append((row['user_id'], nid))\n",
    "\n",
    "interactions_df = pd.DataFrame(user_clicks, columns=['user_id', 'news_id'])\n",
    "interactions_df = interactions_df.merge(news_df, on='news_id', how='left')\n",
    "\n",
    "news_id_to_idx = {nid: i for i, nid in enumerate(news_df['news_id'])}\n",
    "idx_to_news_id = {i: nid for nid, i in news_id_to_idx.items()}\n",
    "news_id_to_title = dict(zip(news_df['news_id'], news_df['title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ad0a5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔢 Fitting TF-IDF...\n"
     ]
    }
   ],
   "source": [
    "print(\"🔢 Fitting TF-IDF...\")\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "tfidf_matrix = tfidf.fit_transform(news_df['content'])\n",
    "\n",
    "def recommend_tfidf(user_id, top_k=5):\n",
    "    user_history = interactions_df[interactions_df['user_id'] == user_id]['news_id'].tolist()\n",
    "    user_idx = [news_id_to_idx[nid] for nid in user_history if nid in news_id_to_idx]\n",
    "    if not user_idx:\n",
    "        return []\n",
    "\n",
    "    user_vector = tfidf_matrix[user_idx].mean(axis=0).A  # to dense NumPy\n",
    "    similarities = cosine_similarity(user_vector, tfidf_matrix).flatten()\n",
    "\n",
    "    recommended_idxs = similarities.argsort()[::-1]\n",
    "    recommended_ids = [idx_to_news_id[i] for i in recommended_idxs if idx_to_news_id[i] not in user_history]\n",
    "    return [(nid, news_id_to_title[nid]) for nid in recommended_ids[:top_k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c796306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Encoding BERT embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████████████████████████████████████████████████████████████████████| 1603/1603 [14:21<00:00,  1.86it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"🤖 Encoding BERT embeddings...\")\n",
    "bert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "bert_embeddings = bert_model.encode(news_df['content'].tolist(), show_progress_bar=True)\n",
    "bert_embeddings = np.array(bert_embeddings)\n",
    "\n",
    "def recommend_bert(user_id, top_k=5):\n",
    "    user_history = interactions_df[interactions_df['user_id'] == user_id]['news_id'].tolist()\n",
    "    user_idx = [news_id_to_idx[nid] for nid in user_history if nid in news_id_to_idx]\n",
    "    if not user_idx:\n",
    "        return []\n",
    "\n",
    "    user_vector = bert_embeddings[user_idx].mean(axis=0).reshape(1, -1)\n",
    "    similarities = cosine_similarity(user_vector, bert_embeddings).flatten()\n",
    "\n",
    "    recommended_idxs = similarities.argsort()[::-1]\n",
    "    recommended_ids = [idx_to_news_id[i] for i in recommended_idxs if idx_to_news_id[i] not in user_history]\n",
    "    return [(nid, news_id_to_title[nid]) for nid in recommended_ids[:top_k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12719fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 Running TF-IDF + BERT example...\n",
      "\n",
      "User: U13740\n",
      "\n",
      "--- TF-IDF Recommendations ---\n",
      "• Biden on being denied communion: 'I'm a practicing Catholic, I practice my faith' (N34069)\n",
      "• Fans fume after 'Wheel of Fortune' seemingly makes mistake (N42154)\n",
      "• Best Response Ever From a 'Wheel of Fortune' Contestant? (N55161)\n",
      "• Former North Carolina US Sen Kay Hagan dies (N61980)\n",
      "• Biden refuses to comment on being denied communion, says he's a 'practicing Catholic' (N19522)\n",
      "\n",
      "--- BERT Recommendations ---\n",
      "• Exclusive: Hunter Biden on getting married after 6 days and why rehab is 'courageous' (N52589)\n",
      "• Best Response Ever From a 'Wheel of Fortune' Contestant? (N55161)\n",
      "• Guy Who 'Doesn't Want Pets' Finally Gives In On His Wedding Day (N18069)\n",
      "• 'It made it too real that we couldn't be here tomorrow': Couple nearly hit by red-light runner, then a miracle happened​ (N2588)\n",
      "• Howard Stern and Wife Beth Remarry After 11 Years in Surprise Wedding   Led by Colton Underwood! (N37327)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n🎯 Running TF-IDF + BERT example...\")\n",
    "for uid in interactions_df['user_id'].unique():\n",
    "    tfidf_recs = recommend_tfidf(uid)\n",
    "    bert_recs = recommend_bert(uid)\n",
    "    if tfidf_recs and bert_recs:\n",
    "        print(f\"\\nUser: {uid}\")\n",
    "        print(\"\\n--- TF-IDF Recommendations ---\")\n",
    "        for nid, title in tfidf_recs:\n",
    "            print(f\"• {title} ({nid})\")\n",
    "\n",
    "        print(\"\\n--- BERT Recommendations ---\")\n",
    "        for nid, title in bert_recs:\n",
    "            print(f\"• {title} ({nid})\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "112918cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ndcg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af990c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_impressions(imp_str):\n",
    "    pairs = imp_str.strip().split()\n",
    "    return [(p.split('-')[0], int(p.split('-')[1])) for p in pairs]\n",
    "\n",
    "def evaluate_ndcg(embedding_matrix, method='bert', k=5):\n",
    "    val_df = pd.read_csv('behaviors_test.tsv', sep='\\t', header=None,\n",
    "                         names=['impression_id', 'user_id', 'time', 'history', 'impressions'])\n",
    "\n",
    "    val_df = val_df.dropna(subset=['history', 'impressions'])\n",
    "\n",
    "    all_ndcg_scores = []\n",
    "\n",
    "    for _, row in tqdm(val_df.iterrows(), total=len(val_df)):\n",
    "        user_history = row['history'].strip().split()\n",
    "        impression = parse_impressions(row['impressions'])\n",
    "\n",
    "        clicked_news = [nid for nid, label in impression if label == 1]\n",
    "        all_news = [nid for nid, _ in impression]\n",
    "\n",
    "        if not clicked_news or not all_news:\n",
    "            continue\n",
    "\n",
    "        # Build user profile vector\n",
    "        user_idx = [news_id_to_idx[nid] for nid in user_history if nid in news_id_to_idx]\n",
    "        if not user_idx:\n",
    "            continue\n",
    "\n",
    "        user_vec = embedding_matrix[user_idx].mean(axis=0).reshape(1, -1)\n",
    "        candidate_idxs = [news_id_to_idx[nid] for nid in all_news if nid in news_id_to_idx]\n",
    "\n",
    "        if len(candidate_idxs) != len(all_news):\n",
    "            continue  # Skip if any news_id is missing\n",
    "\n",
    "        candidate_vecs = embedding_matrix[candidate_idxs]\n",
    "        scores = cosine_similarity(user_vec, candidate_vecs).flatten()\n",
    "\n",
    "        labels = [label for _, label in impression]\n",
    "        score = ndcg_score([labels], [scores], k=k)\n",
    "        all_ndcg_scores.append(score)\n",
    "\n",
    "    return np.mean(all_ndcg_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d7089bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Evaluating nDCG@5 with BERT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 70938/70938 [00:25<00:00, 2781.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ BERT nDCG@5: 0.6379\n",
      "🔍 Evaluating nDCG@10 with BERT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 70938/70938 [00:24<00:00, 2864.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ BERT nDCG@10: 0.6627\n"
     ]
    }
   ],
   "source": [
    "print(\"🔍 Evaluating nDCG@5 with BERT...\")\n",
    "ndcg5 = evaluate_ndcg(bert_embeddings, method='bert', k=5)\n",
    "print(f\"✅ BERT nDCG@5: {ndcg5:.4f}\")\n",
    "\n",
    "print(\"🔍 Evaluating nDCG@10 with BERT...\")\n",
    "ndcg10 = evaluate_ndcg(bert_embeddings, method='bert', k=10)\n",
    "print(f\"✅ BERT nDCG@10: {ndcg10:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b403e3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 70938/70938 [01:31<00:00, 778.46it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6116738240301081"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_ndcg(tfidf_matrix.toarray(), method='tfidf', k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803316b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (News)",
   "language": "python",
   "name": "news310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
