{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fb32fd1-4c0c-4308-a5d6-8443ff55a210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  news_id   category      subcategory  \\\n",
      "0  N55528  lifestyle  lifestyleroyals   \n",
      "1  N19639     health       weightloss   \n",
      "2  N61837       news        newsworld   \n",
      "3  N53526     health           voices   \n",
      "4  N38324     health          medical   \n",
      "\n",
      "                                               title  \\\n",
      "0  The Brands Queen Elizabeth, Prince Charles, an...   \n",
      "1                      50 Worst Habits For Belly Fat   \n",
      "2  The Cost of Trump's Aid Freeze in the Trenches...   \n",
      "3  I Was An NBA Wife. Here's How It Affected My M...   \n",
      "4  How to Get Rid of Skin Tags, According to a De...   \n",
      "\n",
      "                                            abstract  \\\n",
      "0  Shop the notebooks, jackets, and more that the...   \n",
      "1  These seemingly harmless habits are holding yo...   \n",
      "2  Lt. Ivan Molchanets peeked over a parapet of s...   \n",
      "3  I felt like I was a fraud, and being an NBA wi...   \n",
      "4  They seem harmless, but there's a very good re...   \n",
      "\n",
      "                                             url  \\\n",
      "0  https://assets.msn.com/labs/mind/AAGH0ET.html   \n",
      "1  https://assets.msn.com/labs/mind/AAB19MK.html   \n",
      "2  https://assets.msn.com/labs/mind/AAJgNsz.html   \n",
      "3  https://assets.msn.com/labs/mind/AACk2N6.html   \n",
      "4  https://assets.msn.com/labs/mind/AAAKEkt.html   \n",
      "\n",
      "                                      title_entities  \\\n",
      "0  [{\"Label\": \"Prince Philip, Duke of Edinburgh\",...   \n",
      "1  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...   \n",
      "2                                                 []   \n",
      "3                                                 []   \n",
      "4  [{\"Label\": \"Skin tag\", \"Type\": \"C\", \"WikidataI...   \n",
      "\n",
      "                                   abstract_entities  \n",
      "0                                                 []  \n",
      "1  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...  \n",
      "2  [{\"Label\": \"Ukraine\", \"Type\": \"G\", \"WikidataId...  \n",
      "3  [{\"Label\": \"National Basketball Association\", ...  \n",
      "4  [{\"Label\": \"Skin tag\", \"Type\": \"C\", \"WikidataI...  \n",
      "   impression_id user_id                   time  \\\n",
      "0              1  U13740  11/11/2019 9:05:58 AM   \n",
      "1              2  U91836  11/12/2019 6:11:30 PM   \n",
      "2              3  U73700  11/14/2019 7:01:48 AM   \n",
      "3              4  U34670  11/11/2019 5:28:05 AM   \n",
      "4              5   U8125  11/12/2019 4:11:21 PM   \n",
      "\n",
      "                                             history  \\\n",
      "0  N55189 N42782 N34694 N45794 N18445 N63302 N104...   \n",
      "1  N31739 N6072 N63045 N23979 N35656 N43353 N8129...   \n",
      "2  N10732 N25792 N7563 N21087 N41087 N5445 N60384...   \n",
      "3  N45729 N2203 N871 N53880 N41375 N43142 N33013 ...   \n",
      "4                        N10078 N56514 N14904 N33740   \n",
      "\n",
      "                                         impressions  \n",
      "0                                  N55689-1 N35729-0  \n",
      "1  N20678-0 N39317-0 N58114-0 N20495-0 N42977-0 N...  \n",
      "2  N50014-0 N23877-0 N35389-0 N49712-0 N16844-0 N...  \n",
      "3                N35729-0 N33632-0 N49685-1 N27581-0  \n",
      "4  N39985-0 N36050-0 N16096-0 N8400-1 N22407-0 N6...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define paths to the MIND-small dataset\n",
    "news_path = 'MINDsmall_train/news.tsv'\n",
    "behaviors_path = 'MINDsmall_train/behaviors.tsv'\n",
    "\n",
    "# Load data\n",
    "news_df = pd.read_csv(news_path, sep='\\t', header=None,\n",
    "                      names=['news_id', 'category', 'subcategory', 'title', 'abstract', 'url', 'title_entities', 'abstract_entities'])\n",
    "\n",
    "behaviors_df = pd.read_csv(behaviors_path, sep='\\t', header=None,\n",
    "                           names=['impression_id', 'user_id', 'time', 'history', 'impressions'])\n",
    "\n",
    "# Explore data\n",
    "print(news_df.head())\n",
    "print(behaviors_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adc01d3a-d447-4f42-8044-b155b417431e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/smitha/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Clean function for text\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    tokens = [word for word in text.split() if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "news_df['clean_title'] = news_df['title'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "327bb28d-50fa-4c7d-b910-154984a1a14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "\n",
    "# Create mapping from news_id to integer index\n",
    "news_list = news_df['news_id'].tolist()\n",
    "news_id2idx = {nid: idx+1 for idx, nid in enumerate(news_list)}  # +1 for padding=0\n",
    "\n",
    "# Convert user histories into index sequences\n",
    "def encode_history(history_string):\n",
    "    return [news_id2idx[nid] for nid in history_string.split() if nid in news_id2idx]\n",
    "\n",
    "sequences = behaviors_df['history'].dropna().apply(encode_history)\n",
    "sequences = [s for s in sequences if len(s) >= 5]  # keep only long enough histories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce2ff158-dde1-4122-a990-9559f4054cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT4RecDataset(Dataset):\n",
    "    def __init__(self, sequences, max_len=50, mask_prob=0.15):\n",
    "        self.sequences = sequences\n",
    "        self.max_len = max_len\n",
    "        self.mask_prob = mask_prob\n",
    "        self.mask_token = len(news_id2idx) + 1  # use last index for [MASK]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.sequences[idx][-self.max_len:]\n",
    "        seq = [0] * (self.max_len - len(seq)) + seq  # pad on the left\n",
    "\n",
    "        input_ids = seq.copy()\n",
    "        labels = [-100] * self.max_len\n",
    "\n",
    "        for i in range(self.max_len):\n",
    "            if input_ids[i] != 0 and random.random() < self.mask_prob:\n",
    "                labels[i] = input_ids[i]\n",
    "                input_ids[i] = self.mask_token\n",
    "\n",
    "        return torch.tensor(input_ids), torch.tensor(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7c686b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def get_sinusoidal_encoding(seq_len, dim, device):\n",
    "    pe = torch.zeros(seq_len, dim, device=device)\n",
    "    position = torch.arange(0, seq_len, dtype=torch.float, device=device).unsqueeze(1)\n",
    "    div_term = torch.exp(torch.arange(0, dim, 2, device=device).float() * (-math.log(10000.0) / dim))\n",
    "    pe[:, 0::2] = torch.sin(position * div_term)\n",
    "    pe[:, 1::2] = torch.cos(position * div_term)\n",
    "    return pe.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "755d1232-aee1-4936-8473-681753404ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "class BERT4Rec(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=64, num_heads=4, num_layers=2, max_len=50):\n",
    "        super(BERT4Rec, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.token_embed = nn.Embedding(vocab_size + 2, embed_dim, padding_idx=0)  # +2 for mask and pad\n",
    "        encoder_layer = TransformerEncoderLayer(embed_dim, num_heads, batch_first=True)\n",
    "        self.transformer = TransformerEncoder(encoder_layer, num_layers)\n",
    "        self.output_layer = nn.Linear(embed_dim, vocab_size + 1)  # output logits for each token\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        device = input_ids.device\n",
    "        seq_len = input_ids.size(1)\n",
    "        x = self.token_embed(input_ids)\n",
    "        pos_enc = get_sinusoidal_encoding(seq_len, self.embed_dim, device)\n",
    "        x = x + pos_enc\n",
    "        x = self.transformer(x)\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d51b5b1d-1639-435e-bc36-134abb37c842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 8.7381\n",
      "Epoch 2: Loss = 8.5564\n",
      "Epoch 3: Loss = 8.3818\n",
      "Epoch 4: Loss = 8.4325\n",
      "Epoch 5: Loss = 8.4036\n",
      "Epoch 6: Loss = 8.3967\n",
      "Epoch 7: Loss = 8.2226\n",
      "Epoch 8: Loss = 8.2932\n",
      "Epoch 9: Loss = 8.5936\n",
      "Epoch 10: Loss = 8.3075\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = BERT4RecDataset(sequences)\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "model = BERT4Rec(vocab_size=len(news_id2idx))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    for input_ids, labels in dataloader:\n",
    "        logits = model(input_ids)\n",
    "        loss = criterion(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}: Loss = {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ace1fc95-0448-4b36-9a02-047050a35a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations: ['N47020', 'N31801', 'N61864', 'N41375', 'N59704', 'N43142', 'N19347', 'N13429', 'N56753', 'N4607']\n"
     ]
    }
   ],
   "source": [
    "def recommend_bert4rec(user_seq, top_k=10):\n",
    "    model.eval()\n",
    "    encoded = encode_history(user_seq)[-50:]\n",
    "    input_ids = [0] * (50 - len(encoded)) + encoded\n",
    "    input_tensor = torch.tensor([input_ids])\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[0, -1]  # focus on last position\n",
    "        topk = torch.topk(logits, k=top_k).indices.tolist()\n",
    "    idx2news = {v: k for k, v in news_id2idx.items()}\n",
    "    return [idx2news[i] for i in topk if i in idx2news]\n",
    "\n",
    "# Example: generate recommendation\n",
    "user_history = behaviors_df.iloc[0]['history']\n",
    "print(\"Recommendations:\", recommend_bert4rec(user_history))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49092de6-04ad-4474-97a5-aa786c7e46d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_behaviors_df = pd.read_csv(f\"./MINDsmall_dev/behaviors.tsv\", sep='\\t', header=None,\n",
    "                               names=['impression_id', 'user_id', 'time', 'history', 'impressions'])\n",
    "val_behaviors_df['history'] = val_behaviors_df['history'].fillna('')\n",
    "\n",
    "from sklearn.metrics import ndcg_score, label_ranking_average_precision_score\n",
    "\n",
    "def evaluate_model(model, val_df, news_id2idx):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    all_ndcgs = []\n",
    "    all_hits = []\n",
    "\n",
    "    for _, row in val_df.iterrows():\n",
    "        history = [news_id2idx[nid] for nid in row['history'].split() if nid in news_id2idx]\n",
    "        if len(history) == 0:\n",
    "            continue\n",
    "        history = history[-50:]\n",
    "        input_tensor = torch.tensor([history + [0]*(50 - len(history))]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_tensor)\n",
    "            scores = logits[0, -1].cpu().numpy()\n",
    "\n",
    "        impressions = row['impressions'].split()\n",
    "        news_ids = [imp.split('-')[0] for imp in impressions if imp.split('-')[0] in news_id2idx]\n",
    "        labels = [int(imp.split('-')[1]) for imp in impressions if imp.split('-')[0] in news_id2idx]\n",
    "        candidates = [news_id2idx[nid] for nid in news_ids]\n",
    "        candidate_scores = [scores[cid] for cid in candidates]\n",
    "\n",
    "        if len(candidate_scores) > 1 and sum(labels) > 0:\n",
    "            all_ndcgs.append(ndcg_score([labels], [candidate_scores]))\n",
    "            all_hits.append(label_ranking_average_precision_score([labels], [candidate_scores]))\n",
    "\n",
    "    if all_ndcgs:\n",
    "        print(f\"Avg NDCG: {sum(all_ndcgs)/len(all_ndcgs):.4f}\")\n",
    "    if all_hits:\n",
    "        print(f\"Avg MRR: {sum(all_hits)/len(all_hits):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04a3828f-5580-4f22-8cb4-37316aba00b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg NDCG: 0.4162\n",
      "Avg MRR: 0.2469\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, val_behaviors_df, news_id2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703733ed-f1b8-45be-b3ff-3d14a0349ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
