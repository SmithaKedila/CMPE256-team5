{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import gc\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch_geometric in /opt/anaconda3/lib/python3.12/site-packages (2.6.1)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.12/site-packages (from torch_geometric) (3.9.5)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch_geometric) (2024.3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch_geometric) (3.1.4)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from torch_geometric) (1.26.4)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch_geometric) (5.9.0)\n",
      "Requirement already satisfied: pyparsing in /opt/anaconda3/lib/python3.12/site-packages (from torch_geometric) (3.0.9)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from torch_geometric) (2.32.2)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from torch_geometric) (4.66.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->torch_geometric) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->torch_geometric) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->torch_geometric) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->torch_geometric) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->torch_geometric) (1.9.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch_geometric) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torch_geometric) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torch_geometric) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torch_geometric) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torch_geometric) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.read_table(\"./MINDsmall_train/news.tsv\", header=None, names=[\n",
    "    \"news_id\", \"category\", \"subcategory\", \"title\", \"abstract\", \"url\", \"title_entities\", \"abstract_entities\"\n",
    "])\n",
    "\n",
    "behaviors_df = pd.read_table(\"./MINDsmall_train/behaviors.tsv\", header=None, names=[\n",
    "    \"impression_id\", \"user_id\", \"time\", \"history\", \"impressions\"\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News\n",
      "\n",
      "  news_id   category      subcategory  \\\n",
      "0  N55528  lifestyle  lifestyleroyals   \n",
      "1  N19639     health       weightloss   \n",
      "2  N61837       news        newsworld   \n",
      "3  N53526     health           voices   \n",
      "4  N38324     health          medical   \n",
      "\n",
      "                                               title  \\\n",
      "0  The Brands Queen Elizabeth, Prince Charles, an...   \n",
      "1                      50 Worst Habits For Belly Fat   \n",
      "2  The Cost of Trump's Aid Freeze in the Trenches...   \n",
      "3  I Was An NBA Wife. Here's How It Affected My M...   \n",
      "4  How to Get Rid of Skin Tags, According to a De...   \n",
      "\n",
      "                                            abstract  \\\n",
      "0  Shop the notebooks, jackets, and more that the...   \n",
      "1  These seemingly harmless habits are holding yo...   \n",
      "2  Lt. Ivan Molchanets peeked over a parapet of s...   \n",
      "3  I felt like I was a fraud, and being an NBA wi...   \n",
      "4  They seem harmless, but there's a very good re...   \n",
      "\n",
      "                                             url  \\\n",
      "0  https://assets.msn.com/labs/mind/AAGH0ET.html   \n",
      "1  https://assets.msn.com/labs/mind/AAB19MK.html   \n",
      "2  https://assets.msn.com/labs/mind/AAJgNsz.html   \n",
      "3  https://assets.msn.com/labs/mind/AACk2N6.html   \n",
      "4  https://assets.msn.com/labs/mind/AAAKEkt.html   \n",
      "\n",
      "                                      title_entities  \\\n",
      "0  [{\"Label\": \"Prince Philip, Duke of Edinburgh\",...   \n",
      "1  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...   \n",
      "2                                                 []   \n",
      "3                                                 []   \n",
      "4  [{\"Label\": \"Skin tag\", \"Type\": \"C\", \"WikidataI...   \n",
      "\n",
      "                                   abstract_entities  \n",
      "0                                                 []  \n",
      "1  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...  \n",
      "2  [{\"Label\": \"Ukraine\", \"Type\": \"G\", \"WikidataId...  \n",
      "3  [{\"Label\": \"National Basketball Association\", ...  \n",
      "4  [{\"Label\": \"Skin tag\", \"Type\": \"C\", \"WikidataI...  \n",
      "Click behaviors\n",
      "   impression_id user_id                   time  \\\n",
      "0              1  U13740  11/11/2019 9:05:58 AM   \n",
      "1              2  U91836  11/12/2019 6:11:30 PM   \n",
      "2              3  U73700  11/14/2019 7:01:48 AM   \n",
      "3              4  U34670  11/11/2019 5:28:05 AM   \n",
      "4              5   U8125  11/12/2019 4:11:21 PM   \n",
      "\n",
      "                                             history  \\\n",
      "0  N55189 N42782 N34694 N45794 N18445 N63302 N104...   \n",
      "1  N31739 N6072 N63045 N23979 N35656 N43353 N8129...   \n",
      "2  N10732 N25792 N7563 N21087 N41087 N5445 N60384...   \n",
      "3  N45729 N2203 N871 N53880 N41375 N43142 N33013 ...   \n",
      "4                        N10078 N56514 N14904 N33740   \n",
      "\n",
      "                                         impressions  \n",
      "0                                  N55689-1 N35729-0  \n",
      "1  N20678-0 N39317-0 N58114-0 N20495-0 N42977-0 N...  \n",
      "2  N50014-0 N23877-0 N35389-0 N49712-0 N16844-0 N...  \n",
      "3                N35729-0 N33632-0 N49685-1 N27581-0  \n",
      "4  N39985-0 N36050-0 N16096-0 N8400-1 N22407-0 N6...  \n"
     ]
    }
   ],
   "source": [
    "news_df.dropna(subset=['title'], inplace=True)\n",
    "behaviors_df.dropna(subset=['impressions'], inplace=True)\n",
    "print(\"News\\n\")\n",
    "print(news_df.head())\n",
    "print(\"Click behaviors\")\n",
    "print(behaviors_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_clicked_news(imp):\n",
    "    return [i.split('-')[0] for i in imp.split() if i.endswith('-1')]\n",
    "\n",
    "behaviors_df['clicked_news'] = behaviors_df['impressions'].apply(extract_clicked_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_clicks = behaviors_df.explode('clicked_news')[['user_id', 'clicked_news']]\n",
    "user_clicks.columns = ['user_id', 'news_id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique users: 50000, Unique news items: 7713\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "user_encoder = LabelEncoder()\n",
    "item_encoder = LabelEncoder()\n",
    "\n",
    "user_clicks['user_idx'] = user_encoder.fit_transform(user_clicks['user_id'])\n",
    "user_clicks['item_idx'] = item_encoder.fit_transform(user_clicks['news_id'])\n",
    "\n",
    "num_users = user_clicks['user_idx'].nunique()\n",
    "num_items = user_clicks['item_idx'].nunique()\n",
    "print(f\"Unique users: {num_users}, Unique news items: {num_items}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 236344], num_nodes=57713, num_users=50000, num_items=7713)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Convert user and item indices to torch tensors\n",
    "edge_index = torch.tensor([\n",
    "    user_clicks['user_idx'].values,\n",
    "    user_clicks['item_idx'].values + num_users  # shift item indices to avoid overlap\n",
    "], dtype=torch.long)\n",
    "\n",
    "# Create PyG Data object for bipartite graph\n",
    "data = Data(edge_index=edge_index)\n",
    "\n",
    "# Save useful attributes for later use\n",
    "data.num_nodes = num_users + num_items\n",
    "data.num_users = num_users\n",
    "data.num_items = num_items\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LightGCN(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=64, num_layers=3):\n",
    "        super(LightGCN, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.num_nodes = num_users + num_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Initialize user and item embeddings\n",
    "        self.embedding = nn.Embedding(self.num_nodes, embedding_dim)\n",
    "        nn.init.xavier_uniform_(self.embedding.weight)\n",
    "\n",
    "    def forward(self, edge_index):\n",
    "        # Initial embeddings\n",
    "        x = self.embedding.weight\n",
    "\n",
    "        # To accumulate layer-wise embeddings\n",
    "        all_embeddings = [x]\n",
    "\n",
    "        for _ in range(self.num_layers):\n",
    "            # LightGCN propagation: simple mean aggregation from neighbors\n",
    "            row, col = edge_index\n",
    "            deg = torch.bincount(row, minlength=self.num_nodes).float().clamp(min=1)\n",
    "            norm = 1.0 / deg[row].sqrt() / deg[col].sqrt()\n",
    "            x = torch.zeros_like(x).scatter_add_(0, row.unsqueeze(-1).expand(-1, x.size(1)), x[col] * norm.unsqueeze(1))\n",
    "            all_embeddings.append(x)\n",
    "\n",
    "        # Final embedding is the sum of embeddings from all layers\n",
    "        out = torch.stack(all_embeddings, dim=0).mean(dim=0)\n",
    "        return out\n",
    "\n",
    "    def get_user_item_embeddings(self):\n",
    "        out = self.forward(edge_index)\n",
    "        user_emb = out[:self.num_users]\n",
    "        item_emb = out[self.num_users:]\n",
    "        return user_emb, item_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def bpr_loss(user_emb, pos_emb, neg_emb):\n",
    "    pos_scores = torch.sum(user_emb * pos_emb, dim=1)\n",
    "    neg_scores = torch.sum(user_emb * neg_emb, dim=1)\n",
    "    loss = -F.logsigmoid(pos_scores - neg_scores).mean()\n",
    "    return loss\n",
    "\n",
    "def sample_mini_batch(edge_index, num_users, num_items, batch_size):\n",
    "    user_indices = torch.randint(0, num_users, (batch_size,))\n",
    "    pos_items = []\n",
    "    neg_items = []\n",
    "\n",
    "    for u in user_indices:\n",
    "        user_edges = edge_index[1][edge_index[0] == u]\n",
    "        if len(user_edges) == 0:\n",
    "            continue\n",
    "        pos = user_edges[random.randint(0, len(user_edges) - 1)]\n",
    "        while True:\n",
    "            neg = torch.randint(0, num_items, (1,)).item()\n",
    "            if neg + num_users not in user_edges:\n",
    "                break\n",
    "        pos_items.append(pos - num_users)\n",
    "        neg_items.append(neg)\n",
    "\n",
    "    return user_indices, torch.tensor(pos_items), torch.tensor(neg_items)\n",
    "\n",
    "# Set training params\n",
    "embedding_dim = 256\n",
    "num_layers = 3\n",
    "batch_size = 1024\n",
    "epochs = 15\n",
    "learning_rate = 1e-3\n",
    "\n",
    "model = LightGCN(num_users, num_items, embedding_dim, num_layers)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████████████████████████████| 49/49 [00:31<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss: 0.6896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████████████████████████████| 49/49 [00:31<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Loss: 0.6631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████████████████████████████| 49/49 [00:32<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Loss: 0.5936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████████████████████████████| 49/49 [00:33<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Loss: 0.4904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████████████████████████████| 49/49 [00:35<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Loss: 0.3852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████████████████████████████| 49/49 [00:32<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Loss: 0.3106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████████████████████████████| 49/49 [00:32<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Loss: 0.2578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████████████████████████████| 49/49 [00:37<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Loss: 0.2249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████████████████████████████| 49/49 [00:39<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Loss: 0.2042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|█████████████████████████████████| 49/49 [00:39<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Loss: 0.1873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|█████████████████████████████████| 49/49 [00:38<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 - Loss: 0.1712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|█████████████████████████████████| 49/49 [00:35<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 - Loss: 0.1643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|█████████████████████████████████| 49/49 [00:38<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 - Loss: 0.1539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|█████████████████████████████████| 49/49 [00:36<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 - Loss: 0.1485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|█████████████████████████████████| 49/49 [00:36<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 - Loss: 0.1419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    num_batches = data.num_users // batch_size + 1\n",
    "\n",
    "    for _ in trange(num_batches, desc=f\"Epoch {epoch+1}\"):\n",
    "        user_idx, pos_idx, neg_idx = sample_mini_batch(edge_index, num_users, num_items, batch_size)\n",
    "\n",
    "        user_emb, item_emb = model.get_user_item_embeddings()\n",
    "        u_emb = user_emb[user_idx]\n",
    "        pos_emb = item_emb[pos_idx]\n",
    "        neg_emb = item_emb[neg_idx]\n",
    "\n",
    "        loss = bpr_loss(u_emb, pos_emb, neg_emb)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Epoch {epoch+1} - Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nDCG@10 on validation set: 0.6784\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "# Prepare a sample validation set (say, first 1000 impressions)\n",
    "val_behaviors = behaviors_df.head(1000).copy()\n",
    "val_behaviors = val_behaviors[val_behaviors['clicked_news'].map(len) > 0]\n",
    "\n",
    "def prepare_validation_samples(row):\n",
    "    clicked = [i for i in row['clicked_news']]\n",
    "    all_impressions = [i.split('-')[0] for i in row['impressions'].split()]\n",
    "    labels = [1 if news in clicked else 0 for news in all_impressions]\n",
    "    return pd.Series([row['user_id'], all_impressions, labels], index=['user_id', 'candidate_news', 'labels'])\n",
    "\n",
    "val_samples = val_behaviors.apply(prepare_validation_samples, axis=1)\n",
    "\n",
    "# Map news IDs to indices\n",
    "val_samples['user_idx'] = user_encoder.transform(val_samples['user_id'])\n",
    "val_samples['news_indices'] = val_samples['candidate_news'].apply(\n",
    "    lambda news_list: [item_encoder.transform([nid])[0] if nid in item_encoder.classes_ else -1 for nid in news_list]\n",
    ")\n",
    "\n",
    "# Validation function\n",
    "def evaluate_ndcg(model, val_samples, k=10):\n",
    "    model.eval()\n",
    "    user_emb, item_emb = model.get_user_item_embeddings()\n",
    "\n",
    "    ndcgs = []\n",
    "    for _, row in val_samples.iterrows():\n",
    "        user_idx = row['user_idx']\n",
    "        item_idxs = row['news_indices']\n",
    "        labels = row['labels']\n",
    "\n",
    "        # Skip samples with unknown news\n",
    "        if any(idx == -1 for idx in item_idxs):\n",
    "            continue\n",
    "\n",
    "        scores = torch.matmul(user_emb[user_idx], item_emb[item_idxs].T).detach().numpy()\n",
    "        ndcg = ndcg_score([labels], [scores], k=k)\n",
    "        ndcgs.append(ndcg)\n",
    "\n",
    "    return sum(ndcgs) / len(ndcgs) if ndcgs else 0.0\n",
    "\n",
    "# Example usage after training:\n",
    "ndcg10 = evaluate_ndcg(model, val_samples)\n",
    "print(f\"nDCG@10 on validation set: {ndcg10:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model weights\n",
    "torch.save(model.state_dict(), \"lightgcn_model.pth\")\n",
    "\n",
    "# Save embeddings\n",
    "torch.save(user_emb, \"user_embeddings.pt\")\n",
    "torch.save(item_emb, \"item_embeddings.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = []\n",
    "\n",
    "for uid in user_clicks['user_id'].unique():\n",
    "    uidx = user_encoder.transform([uid])[0]\n",
    "    scores = torch.matmul(user_emb[uidx], item_emb.T).detach().numpy()\n",
    "    topk_indices = scores.argsort()[::-1][:10]\n",
    "    topk_news_ids = item_encoder.inverse_transform(topk_indices)\n",
    "    recommendations.append({'user_id': uid, 'top_10_news': topk_news_ids.tolist()})\n",
    "\n",
    "import pandas as pd\n",
    "rec_df = pd.DataFrame(recommendations)\n",
    "rec_df.to_csv(\"user_recommendations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Recommendations for User ID: U1234\n",
      "\n",
      "1. Lamar Odom Is Engaged to Sabrina Parr: See Her Ring!\n",
      "2. Hannah Brown on Being Surrounded By Exes Tyler Cameron and Colton Underwood\n",
      "3. Celebrity plastic surgery transformations\n",
      "4. Stella McCartney Deleted a Meghan Markle Instagram Post After Followers Called Her Out\n",
      "5. 37 Years After His Wife Is Found Dead with an Ax in Her Skull, Husband Is Arrested\n",
      "6. College gymnast dies following training accident in Connecticut\n",
      "7. The son of a Chinese billionaire has been banned from flying first class, playing golf, buying property, or going clubbing\n",
      "8. Carrie Underwood Praises Miranda Lambert as 'Super Supportive': 'We Lift Each Other Up'\n",
      "9. Week in celebrity photos for Nov. 11-15, 2019\n",
      "10. Atlanta college student Alexis Crawford was choked to death, dumped in park, police say\n"
     ]
    }
   ],
   "source": [
    "# 🔍 Set your target user_id here\n",
    "target_user_id = \"U1234\"  # replace with any valid user_id from behaviors_df or user_clicks\n",
    "\n",
    "# Convert to internal user_idx\n",
    "if target_user_id not in user_encoder.classes_:\n",
    "    print(\"User ID not found in training data.\")\n",
    "else:\n",
    "    user_idx = user_encoder.transform([target_user_id])[0]\n",
    "\n",
    "    # Ensure model is in eval mode and get final embeddings\n",
    "    model.eval()\n",
    "    user_emb, item_emb = model.get_user_item_embeddings()\n",
    "\n",
    "    # Compute scores: dot product between user vector and all item vectors\n",
    "    scores = torch.matmul(user_emb[user_idx], item_emb.T).detach().numpy()\n",
    "\n",
    "    # Get top-k recommended item indices (e.g., top 10)\n",
    "    topk_indices = scores.argsort()[::-1][:10]\n",
    "\n",
    "    # Map back to news_id and titles\n",
    "    topk_news_ids = item_encoder.inverse_transform(topk_indices)\n",
    "    topk_titles = news_df.set_index('news_id').loc[topk_news_ids, 'title'].tolist()\n",
    "\n",
    "    # 📢 Print Recommendations\n",
    "    print(f\"\\nTop 10 Recommendations for User ID: {target_user_id}\\n\")\n",
    "    for rank, title in enumerate(topk_titles, 1):\n",
    "        print(f\"{rank}. {title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the models and embeddings\n",
    "user_emb = torch.load(\"user_embeddings.pt\")\n",
    "item_emb = torch.load(\"item_embeddings.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LightGCN(\n",
       "  (embedding): Embedding(57713, 256)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 🔁 Rebuild the model architecture (must match the one used during training)\n",
    "model = LightGCN(num_users, num_items, embedding_dim=256, num_layers=3)\n",
    "\n",
    "# 🔄 Load the trained weights\n",
    "model.load_state_dict(torch.load(\"lightgcn_model.pth\", map_location=torch.device('cpu')))\n",
    "\n",
    "# ✅ Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test samples retained: 335\n"
     ]
    }
   ],
   "source": [
    "# Load dev/test behaviors file\n",
    "dev_behaviors_path = \"MINDsmall_dev/behaviors.tsv\"\n",
    "\n",
    "# Load columns\n",
    "test_behaviors_df = pd.read_table(dev_behaviors_path, header=None, names=[\n",
    "    \"impression_id\", \"user_id\", \"time\", \"history\", \"impressions\"\n",
    "])\n",
    "\n",
    "# Drop impressions with no data\n",
    "test_behaviors_df.dropna(subset=[\"impressions\"], inplace=True)\n",
    "\n",
    "# Extract clicked news and prepare val-like samples\n",
    "def extract_clicked_news(impressions):\n",
    "    return [i.split('-')[0] for i in impressions.split() if i.endswith('-1')]\n",
    "\n",
    "test_behaviors_df['clicked_news'] = test_behaviors_df['impressions'].apply(extract_clicked_news)\n",
    "\n",
    "# Keep only valid samples (at least one click)\n",
    "test_behaviors = test_behaviors_df[test_behaviors_df['clicked_news'].map(len) > 0].copy()\n",
    "\n",
    "# Convert into format compatible with evaluate_ndcg()\n",
    "def prepare_test_sample(row):\n",
    "    clicked = row['clicked_news']\n",
    "    all_news = [i.split('-')[0] for i in row['impressions'].split()]\n",
    "    labels = [1 if n in clicked else 0 for n in all_news]\n",
    "    return pd.Series([row['user_id'], all_news, labels], index=['user_id', 'candidate_news', 'labels'])\n",
    "\n",
    "test_samples = test_behaviors.apply(prepare_test_sample, axis=1)\n",
    "\n",
    "# Map user and news IDs to internal indices\n",
    "test_samples['user_idx'] = test_samples['user_id'].apply(\n",
    "    lambda uid: user_encoder.transform([uid])[0] if uid in user_encoder.classes_ else -1\n",
    ")\n",
    "\n",
    "test_samples['news_indices'] = test_samples['candidate_news'].apply(\n",
    "    lambda news_list: [item_encoder.transform([nid])[0] if nid in item_encoder.classes_ else -1 for nid in news_list]\n",
    ")\n",
    "\n",
    "# Optional: remove samples with unknown users or items\n",
    "test_samples = test_samples[(test_samples['user_idx'] != -1) & \n",
    "                            (test_samples['news_indices'].apply(lambda x: -1 not in x))]\n",
    "\n",
    "print(f\"Test samples retained: {len(test_samples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nDCG@10 on MINDsmall_dev test set: 0.7913\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "def evaluate_ndcg(model, val_samples, k=10):\n",
    "    model.eval()\n",
    "    user_emb, item_emb = model.get_user_item_embeddings()\n",
    "\n",
    "    ndcgs = []\n",
    "    for _, row in val_samples.iterrows():\n",
    "        user_idx = row['user_idx']\n",
    "        item_idxs = row['news_indices']\n",
    "        labels = row['labels']\n",
    "\n",
    "        # Skip samples with unknown news\n",
    "        if any(idx == -1 for idx in item_idxs):\n",
    "            continue\n",
    "\n",
    "        scores = torch.matmul(user_emb[user_idx], item_emb[item_idxs].T).detach().numpy()\n",
    "        ndcg = ndcg_score([labels], [scores], k=k)\n",
    "        ndcgs.append(ndcg)\n",
    "\n",
    "    return sum(ndcgs) / len(ndcgs) if ndcgs else 0.0\n",
    "    \n",
    "ndcg10_test = evaluate_ndcg(model, test_samples)\n",
    "print(f\"nDCG@10 on MINDsmall_dev test set: {ndcg10_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
