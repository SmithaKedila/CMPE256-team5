{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import gc\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch_geometric in ./anaconda3/lib/python3.12/site-packages (2.6.1)\n",
      "Requirement already satisfied: aiohttp in ./anaconda3/lib/python3.12/site-packages (from torch_geometric) (3.11.16)\n",
      "Requirement already satisfied: fsspec in ./anaconda3/lib/python3.12/site-packages (from torch_geometric) (2024.6.1)\n",
      "Requirement already satisfied: jinja2 in ./anaconda3/lib/python3.12/site-packages (from torch_geometric) (3.1.4)\n",
      "Requirement already satisfied: numpy in ./anaconda3/lib/python3.12/site-packages (from torch_geometric) (1.26.4)\n",
      "Requirement already satisfied: psutil>=5.8.0 in ./anaconda3/lib/python3.12/site-packages (from torch_geometric) (5.9.0)\n",
      "Requirement already satisfied: pyparsing in ./anaconda3/lib/python3.12/site-packages (from torch_geometric) (3.1.2)\n",
      "Requirement already satisfied: requests in ./anaconda3/lib/python3.12/site-packages (from torch_geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in ./anaconda3/lib/python3.12/site-packages (from torch_geometric) (4.66.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./anaconda3/lib/python3.12/site-packages (from aiohttp->torch_geometric) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./anaconda3/lib/python3.12/site-packages (from aiohttp->torch_geometric) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./anaconda3/lib/python3.12/site-packages (from aiohttp->torch_geometric) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./anaconda3/lib/python3.12/site-packages (from aiohttp->torch_geometric) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./anaconda3/lib/python3.12/site-packages (from aiohttp->torch_geometric) (6.0.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./anaconda3/lib/python3.12/site-packages (from aiohttp->torch_geometric) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./anaconda3/lib/python3.12/site-packages (from aiohttp->torch_geometric) (1.19.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./anaconda3/lib/python3.12/site-packages (from jinja2->torch_geometric) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./anaconda3/lib/python3.12/site-packages (from requests->torch_geometric) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/lib/python3.12/site-packages (from requests->torch_geometric) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./anaconda3/lib/python3.12/site-packages (from requests->torch_geometric) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.12/site-packages (from requests->torch_geometric) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.read_table(\"Documents/CMPE256/256-Project/MINDsmall_train/news.tsv\", header=None, names=[\n",
    "    \"news_id\", \"category\", \"subcategory\", \"title\", \"abstract\", \"url\", \"title_entities\", \"abstract_entities\"\n",
    "])\n",
    "\n",
    "behaviors_df = pd.read_table(\"Documents/CMPE256/256-Project/MINDsmall_train/behaviors.tsv\", header=None, names=[\n",
    "    \"impression_id\", \"user_id\", \"time\", \"history\", \"impressions\"\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing: Cleaning the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News\n",
      "\n",
      "  news_id   category      subcategory  \\\n",
      "0  N55528  lifestyle  lifestyleroyals   \n",
      "1  N19639     health       weightloss   \n",
      "2  N61837       news        newsworld   \n",
      "3  N53526     health           voices   \n",
      "4  N38324     health          medical   \n",
      "\n",
      "                                               title  \\\n",
      "0  The Brands Queen Elizabeth, Prince Charles, an...   \n",
      "1                      50 Worst Habits For Belly Fat   \n",
      "2  The Cost of Trump's Aid Freeze in the Trenches...   \n",
      "3  I Was An NBA Wife. Here's How It Affected My M...   \n",
      "4  How to Get Rid of Skin Tags, According to a De...   \n",
      "\n",
      "                                            abstract  \\\n",
      "0  Shop the notebooks, jackets, and more that the...   \n",
      "1  These seemingly harmless habits are holding yo...   \n",
      "2  Lt. Ivan Molchanets peeked over a parapet of s...   \n",
      "3  I felt like I was a fraud, and being an NBA wi...   \n",
      "4  They seem harmless, but there's a very good re...   \n",
      "\n",
      "                                             url  \\\n",
      "0  https://assets.msn.com/labs/mind/AAGH0ET.html   \n",
      "1  https://assets.msn.com/labs/mind/AAB19MK.html   \n",
      "2  https://assets.msn.com/labs/mind/AAJgNsz.html   \n",
      "3  https://assets.msn.com/labs/mind/AACk2N6.html   \n",
      "4  https://assets.msn.com/labs/mind/AAAKEkt.html   \n",
      "\n",
      "                                      title_entities  \\\n",
      "0  [{\"Label\": \"Prince Philip, Duke of Edinburgh\",...   \n",
      "1  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...   \n",
      "2                                                 []   \n",
      "3                                                 []   \n",
      "4  [{\"Label\": \"Skin tag\", \"Type\": \"C\", \"WikidataI...   \n",
      "\n",
      "                                   abstract_entities  \n",
      "0                                                 []  \n",
      "1  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...  \n",
      "2  [{\"Label\": \"Ukraine\", \"Type\": \"G\", \"WikidataId...  \n",
      "3  [{\"Label\": \"National Basketball Association\", ...  \n",
      "4  [{\"Label\": \"Skin tag\", \"Type\": \"C\", \"WikidataI...  \n",
      "Click behaviors\n",
      "   impression_id user_id                   time  \\\n",
      "0              1  U13740  11/11/2019 9:05:58 AM   \n",
      "1              2  U91836  11/12/2019 6:11:30 PM   \n",
      "2              3  U73700  11/14/2019 7:01:48 AM   \n",
      "3              4  U34670  11/11/2019 5:28:05 AM   \n",
      "4              5   U8125  11/12/2019 4:11:21 PM   \n",
      "\n",
      "                                             history  \\\n",
      "0  N55189 N42782 N34694 N45794 N18445 N63302 N104...   \n",
      "1  N31739 N6072 N63045 N23979 N35656 N43353 N8129...   \n",
      "2  N10732 N25792 N7563 N21087 N41087 N5445 N60384...   \n",
      "3  N45729 N2203 N871 N53880 N41375 N43142 N33013 ...   \n",
      "4                        N10078 N56514 N14904 N33740   \n",
      "\n",
      "                                         impressions  \n",
      "0                                  N55689-1 N35729-0  \n",
      "1  N20678-0 N39317-0 N58114-0 N20495-0 N42977-0 N...  \n",
      "2  N50014-0 N23877-0 N35389-0 N49712-0 N16844-0 N...  \n",
      "3                N35729-0 N33632-0 N49685-1 N27581-0  \n",
      "4  N39985-0 N36050-0 N16096-0 N8400-1 N22407-0 N6...  \n"
     ]
    }
   ],
   "source": [
    "news_df.dropna(subset=['title'], inplace=True)\n",
    "behaviors_df.dropna(subset=['impressions'], inplace=True)\n",
    "print(\"News\\n\")\n",
    "print(news_df.head())\n",
    "print(\"Click behaviors\")\n",
    "print(behaviors_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the clicked news from behaviors dataset with news ids marked with 1(representing clicked news) and thus adding a new column of clicked_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_clicked_news(imp):\n",
    "    return [i.split('-')[0] for i in imp.split() if i.endswith('-1')]\n",
    "\n",
    "behaviors_df['clicked_news'] = behaviors_df['impressions'].apply(extract_clicked_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_clicks = behaviors_df.explode('clicked_news')[['user_id', 'clicked_news']]\n",
    "user_clicks.columns = ['user_id', 'news_id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique users: 50000, Unique news items: 7713\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "user_encoder = LabelEncoder()\n",
    "item_encoder = LabelEncoder()\n",
    "\n",
    "user_clicks['user_idx'] = user_encoder.fit_transform(user_clicks['user_id'])\n",
    "user_clicks['item_idx'] = item_encoder.fit_transform(user_clicks['news_id'])\n",
    "\n",
    "num_users = user_clicks['user_idx'].nunique()\n",
    "num_items = user_clicks['item_idx'].nunique()\n",
    "print(f\"Unique users: {num_users}, Unique news items: {num_items}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 236344], num_nodes=57713, num_users=50000, num_items=7713)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Convert user and item indices to torch tensors\n",
    "edge_index = torch.tensor([\n",
    "    user_clicks['user_idx'].values,\n",
    "    user_clicks['item_idx'].values + num_users  # shift item indices to avoid overlap\n",
    "], dtype=torch.long)\n",
    "\n",
    "# Create PyG Data object for bipartite graph\n",
    "data = Data(edge_index=edge_index)\n",
    "\n",
    "# Save useful attributes for later use\n",
    "data.num_nodes = num_users + num_items\n",
    "data.num_users = num_users\n",
    "data.num_items = num_items\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LightGCN(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=64, num_layers=3):\n",
    "        super(LightGCN, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.num_nodes = num_users + num_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Initialize user and item embeddings\n",
    "        self.embedding = nn.Embedding(self.num_nodes, embedding_dim)\n",
    "        nn.init.xavier_uniform_(self.embedding.weight)\n",
    "\n",
    "    def forward(self, edge_index):\n",
    "        # Initial embeddings\n",
    "        x = self.embedding.weight\n",
    "\n",
    "        # To accumulate layer-wise embeddings\n",
    "        all_embeddings = [x]\n",
    "\n",
    "        for _ in range(self.num_layers):\n",
    "            # LightGCN propagation: simple mean aggregation from neighbors\n",
    "            row, col = edge_index\n",
    "            deg = torch.bincount(row, minlength=self.num_nodes).float().clamp(min=1)\n",
    "            norm = 1.0 / deg[row].sqrt() / deg[col].sqrt()\n",
    "            x = torch.zeros_like(x).scatter_add_(0, row.unsqueeze(-1).expand(-1, x.size(1)), x[col] * norm.unsqueeze(1))\n",
    "            all_embeddings.append(x)\n",
    "\n",
    "        # Final embedding is the sum of embeddings from all layers\n",
    "        out = torch.stack(all_embeddings, dim=0).mean(dim=0)\n",
    "        return out\n",
    "\n",
    "    def get_user_item_embeddings(self):\n",
    "        out = self.forward(edge_index)\n",
    "        user_emb = out[:self.num_users]\n",
    "        item_emb = out[self.num_users:]\n",
    "        return user_emb, item_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def bpr_loss(user_emb, pos_emb, neg_emb):\n",
    "    pos_scores = torch.sum(user_emb * pos_emb, dim=1)\n",
    "    neg_scores = torch.sum(user_emb * neg_emb, dim=1)\n",
    "    loss = -F.logsigmoid(pos_scores - neg_scores).mean()\n",
    "    return loss\n",
    "\n",
    "def sample_mini_batch(edge_index, num_users, num_items, batch_size):\n",
    "    user_indices = torch.randint(0, num_users, (batch_size,))\n",
    "    pos_items = []\n",
    "    neg_items = []\n",
    "\n",
    "    for u in user_indices:\n",
    "        user_edges = edge_index[1][edge_index[0] == u]\n",
    "        if len(user_edges) == 0:\n",
    "            continue\n",
    "        pos = user_edges[random.randint(0, len(user_edges) - 1)]\n",
    "        while True:\n",
    "            neg = torch.randint(0, num_items, (1,)).item()\n",
    "            if neg + num_users not in user_edges:\n",
    "                break\n",
    "        pos_items.append(pos - num_users)\n",
    "        neg_items.append(neg)\n",
    "\n",
    "    return user_indices, torch.tensor(pos_items), torch.tensor(neg_items)\n",
    "\n",
    "# Set training params\n",
    "embedding_dim = 256\n",
    "num_layers = 3\n",
    "batch_size = 1024\n",
    "epochs = 15\n",
    "learning_rate = 1e-3\n",
    "\n",
    "model = LightGCN(num_users, num_items, embedding_dim, num_layers)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the models and embeddings\n",
    "user_emb = torch.load(\"Documents/CMPE256/256-Project/user_embeddings.pt\")\n",
    "item_emb = torch.load(\"Documents/CMPE256/256-Project/item_embeddings.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LightGCN(\n",
       "  (embedding): Embedding(57713, 256)\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rebuild the model architecture (must match the one used during training)\n",
    "model = LightGCN(num_users, num_items, embedding_dim=256, num_layers=3)\n",
    "\n",
    "# Load the trained weights\n",
    "model.load_state_dict(torch.load(\"Documents/CMPE256/256-Project/lightgcn_model.pth\", map_location=torch.device('cpu')))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nDCG@10 on MINDsmall_dev test set: 0.7940\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "def evaluate_ndcg(model, val_samples, k=10):\n",
    "    model.eval()\n",
    "    user_emb, item_emb = model.get_user_item_embeddings()\n",
    "\n",
    "    ndcgs = []\n",
    "    for _, row in val_samples.iterrows():\n",
    "        user_idx = row['user_idx']\n",
    "        item_idxs = row['news_indices']\n",
    "        labels = row['labels']\n",
    "\n",
    "        # Skip samples with unknown news\n",
    "        if any(idx == -1 for idx in item_idxs):\n",
    "            continue\n",
    "\n",
    "        scores = torch.matmul(user_emb[user_idx], item_emb[item_idxs].T).detach().numpy()\n",
    "        ndcg = ndcg_score([labels], [scores], k=k)\n",
    "        ndcgs.append(ndcg)\n",
    "\n",
    "    return sum(ndcgs) / len(ndcgs) if ndcgs else 0.0\n",
    "    \n",
    "ndcg10_test = evaluate_ndcg(model, test_samples)\n",
    "print(f\"nDCG@10 on MINDsmall_dev test set: {ndcg10_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Embeddings Shape: torch.Size([51282, 5000])\n",
      "BERT Embeddings Shape: torch.Size([51282, 384])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('Documents/CMPE256/256-Project/tfidf_vectorizer.pt', 'rb') as f:\n",
    "    tfidf_vectorizer = pickle.load(f)\n",
    "\n",
    "tfidf_embeddings = torch.load('Documents/CMPE256/256-Project/tfidf_embeddings.pt')  # TF-IDF representation of news articles\n",
    "\n",
    "# Load BERT Embeddings (semantic content embeddings)\n",
    "bert_embeddings = torch.load('Documents/CMPE256/256-Project/bert_embeddings.pt')  # Precomputed BERT embeddings for news articles\n",
    "\n",
    "print(f\"TF-IDF Embeddings Shape: {tfidf_embeddings.shape}\")\n",
    "print(f\"BERT Embeddings Shape: {bert_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "class BERT4Rec(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=64, num_heads=4, num_layers=2, max_len=50):\n",
    "        super(BERT4Rec, self).__init__()\n",
    "        self.token_embed = nn.Embedding(vocab_size + 2, embed_dim, padding_idx=0)  # +2 for mask and pad\n",
    "        encoder_layer = TransformerEncoderLayer(embed_dim, num_heads, batch_first=True)\n",
    "        self.transformer = TransformerEncoder(encoder_layer, num_layers)\n",
    "        self.output_layer = nn.Linear(embed_dim, vocab_size + 1)  # output logits for each token\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        x = self.token_embed(input_ids)\n",
    "        x = self.transformer(x)\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT4Rec User Embeddings Shape: torch.Size([51284, 64])\n",
      "BERT4Rec full model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load BERT4Rec user embeddings\n",
    "bert4rec_user_embeddings = np.load('Documents/CMPE256/256-Project/bert4rec_embeddings.npy')  # shape: (num_users, embedding_dim)\n",
    "bert4rec_user_embeddings = torch.tensor(bert4rec_user_embeddings)\n",
    "\n",
    "print(f\"BERT4Rec User Embeddings Shape: {bert4rec_user_embeddings.shape}\")\n",
    "\n",
    "# Create mapping from news_id to integer index\n",
    "news_list = news_df['news_id'].tolist()\n",
    "news_id2idx = {nid: idx+1 for idx, nid in enumerate(news_list)}  # +1 for padding=0\n",
    "# Load the full BERT4Rec model directly (NOT state_dict)\n",
    "bert4rec_model = torch.load('Documents/CMPE256/256-Project/bert4rec_full_model.pth', map_location=torch.device('cpu'), weights_only=False)\n",
    "\n",
    "# Set to evaluation mode\n",
    "bert4rec_model.eval()\n",
    "\n",
    "print(\"BERT4Rec full model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation of scores from each model to be combined using weighted ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_gnn(user_id, user_encoder, item_encoder, model, edge_index=None):\n",
    "    \"\"\"\n",
    "    Computes GNN scores for a user.\n",
    "    \"\"\"\n",
    "    if user_id not in user_encoder.classes_:\n",
    "        return None\n",
    "\n",
    "    user_idx = user_encoder.transform([user_id])[0]\n",
    "    user_emb, item_emb = model.get_user_item_embeddings()\n",
    "\n",
    "    scores = torch.matmul(user_emb[user_idx], item_emb.T).detach().numpy()\n",
    "    return scores\n",
    "\n",
    "\n",
    "def score_tfidf(user_id, interactions_df, tfidf_embeddings, tfidf_vectorizer, user_encoder, news_id_to_idx):\n",
    "    \"\"\"\n",
    "    Computes TF-IDF scores for a user.\n",
    "    \"\"\"\n",
    "    if user_id not in user_encoder.classes_:\n",
    "        return None\n",
    "\n",
    "    user_clicked = interactions_df[interactions_df['user_id'] == user_id]['news_id'].tolist()\n",
    "    clicked_idx = [news_id_to_idx.get(nid, None) for nid in user_clicked]\n",
    "    clicked_idx = [idx for idx in clicked_idx if idx is not None]\n",
    "\n",
    "    if not clicked_idx:\n",
    "        return np.zeros(tfidf_embeddings.shape[0])\n",
    "\n",
    "    user_vector = tfidf_embeddings[clicked_idx].mean(axis=0, keepdim=True)\n",
    "    similarities = cosine_similarity(user_vector, tfidf_embeddings).flatten()\n",
    "\n",
    "    return similarities\n",
    "\n",
    "def score_bert(user_id, interactions_df, bert_embeddings, user_encoder, news_id_to_idx):\n",
    "    \"\"\"\n",
    "    Computes BERT content similarity scores for a user.\n",
    "    \"\"\"\n",
    "    if user_id not in user_encoder.classes_:\n",
    "        return None\n",
    "\n",
    "    user_clicked = interactions_df[interactions_df['user_id'] == user_id]['news_id'].tolist()\n",
    "    clicked_idx = [news_id_to_idx.get(nid, None) for nid in user_clicked]\n",
    "    clicked_idx = [idx for idx in clicked_idx if idx is not None]\n",
    "\n",
    "    if not clicked_idx:\n",
    "        return np.zeros(bert_embeddings.shape[0])\n",
    "\n",
    "    user_vector = bert_embeddings[clicked_idx].mean(dim=0)\n",
    "    scores = torch.matmul(user_vector, bert_embeddings.T).detach().numpy()\n",
    "\n",
    "    return scores\n",
    "\n",
    "def score_bert4rec(user_id, user_encoder, bert4rec_user_embeddings):\n",
    "    \"\"\"\n",
    "    Computes BERT4Rec user embedding scores.\n",
    "    \"\"\"\n",
    "    if user_id not in user_encoder.classes_:\n",
    "        return None\n",
    "\n",
    "    user_idx = user_encoder.transform([user_id])[0]\n",
    "\n",
    "    if user_idx >= bert4rec_user_embeddings.shape[0]:\n",
    "        return np.zeros(bert4rec_user_embeddings.shape[1])\n",
    "\n",
    "    user_emb = bert4rec_user_embeddings[user_idx]\n",
    "    scores = torch.matmul(user_emb, bert4rec_user_embeddings.T).detach().numpy()\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created all missing mappings: interactions_df, news_id_to_idx, idx_to_news_id, news_id_to_title.\n"
     ]
    }
   ],
   "source": [
    "# interactions_df: user_id ↔ news_id clicked\n",
    "try:\n",
    "    interactions_df\n",
    "except NameError:\n",
    "    interactions_df = user_clicks[['user_id', 'news_id']]\n",
    "\n",
    "# news_id_to_idx and idx_to_news_id mappings\n",
    "try:\n",
    "    news_id_to_idx\n",
    "    idx_to_news_id\n",
    "except NameError:\n",
    "    news_id_to_idx = {nid: idx for idx, nid in enumerate(news_df['news_id'].tolist())}\n",
    "    idx_to_news_id = {idx: nid for nid, idx in news_id_to_idx.items()}\n",
    "\n",
    "# news_id_to_title mapping\n",
    "try:\n",
    "    news_id_to_title\n",
    "except NameError:\n",
    "    news_id_to_title = dict(zip(news_df['news_id'], news_df['title']))\n",
    "\n",
    "print(\"Created all missing mappings: interactions_df, news_id_to_idx, idx_to_news_id, news_id_to_title.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to blend all the models with weightage defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def blended_recommendation(\n",
    "    user_id,\n",
    "    user_encoder,\n",
    "    item_encoder,\n",
    "    model,\n",
    "    edge_index,\n",
    "    interactions_df,\n",
    "    tfidf_embeddings,\n",
    "    tfidf_vectorizer,\n",
    "    bert_embeddings,\n",
    "    bert4rec_user_embeddings,\n",
    "    news_id_to_idx,\n",
    "    alpha=0.4,\n",
    "    beta=0.2,\n",
    "    gamma=0.2,\n",
    "    delta=0.2,\n",
    "    top_k=10,\n",
    "    candidate_news_ids=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate blended recommendations by scoring only on candidate news articles.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # --- Candidate news list ---\n",
    "    if candidate_news_ids is not None:\n",
    "        candidate_indices = [news_id_to_idx.get(nid, -1) for nid in candidate_news_ids if nid in news_id_to_idx]\n",
    "    else:\n",
    "        candidate_indices = list(range(tfidf_embeddings.shape[0]))\n",
    "\n",
    "    # --- GNN Scores ---\n",
    "    gnn_user_emb, gnn_item_emb = model.get_user_item_embeddings()\n",
    "    \n",
    "    if user_id not in user_encoder.classes_:\n",
    "        return []\n",
    "\n",
    "    user_idx = user_encoder.transform([user_id])[0]\n",
    "\n",
    "    gnn_raw_scores = torch.matmul(gnn_user_emb[user_idx], gnn_item_emb.T).detach().cpu().numpy()\n",
    "\n",
    "    # Fill missing gnn scores\n",
    "    full_size = tfidf_embeddings.shape[0]\n",
    "    expanded_gnn_scores = np.full(full_size, -np.inf)\n",
    "    expanded_gnn_scores[:len(gnn_raw_scores)] = gnn_raw_scores\n",
    "\n",
    "    gnn_scores = expanded_gnn_scores[candidate_indices]\n",
    "\n",
    "    # --- TF-IDF Scores ---\n",
    "    tfidf_scores_full = score_tfidf(user_id, interactions_df, tfidf_embeddings, tfidf_vectorizer, user_encoder, news_id_to_idx)\n",
    "    tfidf_scores = tfidf_scores_full[candidate_indices]\n",
    "\n",
    "    # --- BERT Scores ---\n",
    "    bert_scores_full = score_bert(user_id, interactions_df, bert_embeddings, user_encoder, news_id_to_idx)\n",
    "    bert_scores = bert_scores_full[candidate_indices]\n",
    "\n",
    "    # --- BERT4Rec Scores ---\n",
    "    bert4rec_scores_full = score_bert4rec(user_id, user_encoder, bert4rec_user_embeddings)\n",
    "    bert4rec_scores = bert4rec_scores_full[candidate_indices]\n",
    "\n",
    "    def normalize(x):\n",
    "        x = np.nan_to_num(x)\n",
    "        if x.size == 0:\n",
    "            return x  # return empty safely\n",
    "        min_x = np.min(x)\n",
    "        max_x = np.max(x)\n",
    "        if max_x - min_x == 0:\n",
    "            return np.zeros_like(x)\n",
    "        return (x - min_x) / (max_x - min_x)\n",
    "\n",
    "    gnn_scores = normalize(gnn_scores)\n",
    "    tfidf_scores = normalize(tfidf_scores)\n",
    "    bert_scores = normalize(bert_scores)\n",
    "    bert4rec_scores = normalize(bert4rec_scores)\n",
    "\n",
    "    # --- Blend all normalized scores ---\n",
    "    final_scores = (\n",
    "        alpha * gnn_scores +\n",
    "        beta * tfidf_scores +\n",
    "        gamma * bert_scores +\n",
    "        delta * bert4rec_scores\n",
    "    )\n",
    "\n",
    "    # --- Pick top-k\n",
    "    top_indices = np.argsort(final_scores)[::-1][:top_k]\n",
    "\n",
    "    if candidate_news_ids is not None:\n",
    "        top_news_ids = [candidate_news_ids[i] for i in top_indices]\n",
    "    else:\n",
    "        top_news_ids = item_encoder.inverse_transform(top_indices)\n",
    "\n",
    "    return top_news_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction of top 10 news for any given user id from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_for_user(\n",
    "    user_id,\n",
    "    user_encoder,\n",
    "    item_encoder,\n",
    "    model,\n",
    "    edge_index,\n",
    "    interactions_df,\n",
    "    tfidf_embeddings,\n",
    "    tfidf_vectorizer,\n",
    "    bert_embeddings,\n",
    "    bert4rec_user_embeddings,\n",
    "    news_id_to_idx,\n",
    "    top_k=10,\n",
    "    alpha=0.4,\n",
    "    beta=0.2,\n",
    "    gamma=0.2,\n",
    "    delta=0.2\n",
    "):\n",
    "    \"\"\"\n",
    "    Predict Top-K news articles for a given user using the blended model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Call blended_recommendation (predict across all news if no candidate list)\n",
    "    top_news_ids = blended_recommendation(\n",
    "        user_id=user_id,\n",
    "        user_encoder=user_encoder,\n",
    "        item_encoder=item_encoder,\n",
    "        model=model,\n",
    "        edge_index=edge_index,\n",
    "        interactions_df=interactions_df,\n",
    "        tfidf_embeddings=tfidf_embeddings,\n",
    "        tfidf_vectorizer=tfidf_vectorizer,\n",
    "        bert_embeddings=bert_embeddings,\n",
    "        bert4rec_user_embeddings=bert4rec_user_embeddings,\n",
    "        news_id_to_idx=news_id_to_idx,\n",
    "        alpha=alpha,\n",
    "        beta=beta,\n",
    "        gamma=gamma,\n",
    "        delta=delta,\n",
    "        top_k=top_k,\n",
    "        candidate_news_ids=None  # Predict across all news if not specified\n",
    "    )\n",
    "\n",
    "    return top_news_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 Recommended News for User U12345:\n",
      "1. Texas Plane Crashed After Dropping Water For Gender Reveal: NTSB\n",
      "2. 7 Rules for How to Call in Sick to Work\n",
      "3. Some Burning Steelers Questions about Mike Tomlin\n",
      "4. Rudy Giuliani's globetrotting complicates US foreign policy\n",
      "5. No 'Ralphie' for a second straight game leaves CU fans concerned\n",
      "6. Coast Guard suspends search for missing airman\n",
      "7. Watch: Fans go crazy when Burrow arrives back in Baton Rouge after win over Tide\n",
      "8. Fear spreads among Iraqi protesters as government cracks down, keeps death toll secret\n",
      "9. Fastest American Muscle Cars EVER\n",
      "10. Walmart sales hit all-time high\n"
     ]
    }
   ],
   "source": [
    "target_user_id = \"U12345\"  # Replace with a valid user ID\n",
    "predicted_top_news = predict_for_user(\n",
    "    user_id=target_user_id,\n",
    "    user_encoder=user_encoder,\n",
    "    item_encoder=item_encoder,\n",
    "    model=model,\n",
    "    edge_index=edge_index,\n",
    "    interactions_df=interactions_df,\n",
    "    tfidf_embeddings=tfidf_embeddings,\n",
    "    tfidf_vectorizer=tfidf_vectorizer,\n",
    "    bert_embeddings=bert_embeddings,\n",
    "    bert4rec_user_embeddings=bert4rec_user_embeddings,\n",
    "    news_id_to_idx=news_id_to_idx,\n",
    "    top_k=10\n",
    ")\n",
    "\n",
    "print(f\"Top-10 Recommended News for User {target_user_id}:\")\n",
    "for idx, news_id in enumerate(predicted_top_news, 1):\n",
    "    title = news_id_to_title.get(news_id, \"Unknown Title\")\n",
    "    print(f\"{idx}. {title}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data for validation from MIND dev dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load behaviors.tsv if not already ---\n",
    "behaviors_df = pd.read_csv('Documents/CMPE256/256-Project/MINDsmall_dev/behaviors.tsv', sep='\\t', header=None,\n",
    "                           names=['impression_id', 'user_id', 'time', 'history', 'impressions'])\n",
    "\n",
    "# --- Drop rows with no impressions ---\n",
    "behaviors_df.dropna(subset=['history'], inplace=True)\n",
    "\n",
    "# --- Extract clicked news from impressions (correct way) ---\n",
    "def extract_clicked_news(impressions):\n",
    "    return [imp.split('-')[0] for imp in impressions.split() if imp.endswith('-1')]\n",
    "\n",
    "behaviors_df['clicked_news'] = behaviors_df['impressions'].apply(extract_clicked_news)\n",
    "\n",
    "# --- Filter sessions with at least one click ---\n",
    "test_behaviors = behaviors_df[behaviors_df['clicked_news'].map(len) > 0].copy()\n",
    "\n",
    "# --- Prepare test_samples exactly like GNN evaluation ---\n",
    "def prepare_test_sample(row):\n",
    "    clicked = row['clicked_news']\n",
    "    all_news = [imp.split('-')[0] for imp in row['impressions'].split()]\n",
    "    labels = [1 if n in clicked else 0 for n in all_news]\n",
    "    return pd.Series([row['user_id'], all_news, labels], index=['user_id', 'candidate_news', 'labels'])\n",
    "\n",
    "test_samples = test_behaviors.apply(prepare_test_sample, axis=1)\n",
    "\n",
    "# --- Filter only seen users ---\n",
    "test_samples = test_samples[test_samples['user_id'].isin(user_encoder.classes_)].copy()\n",
    "\n",
    "# --- Map to user indices and news indices ---\n",
    "test_samples['user_idx'] = user_encoder.transform(test_samples['user_id'])\n",
    "\n",
    "test_samples['news_indices'] = test_samples['candidate_news'].apply(\n",
    "    lambda news_list: [item_encoder.transform([nid])[0] if nid in item_encoder.classes_ else -1 for nid in news_list]\n",
    ")\n",
    "\n",
    "# --- Drop samples with -1 indices (unknown news) ---\n",
    "test_samples = test_samples[(test_samples['news_indices'].apply(lambda x: all(idx != -1 for idx in x)))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nDCG@10 for Blended Model: 0.7401\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "def evaluate_blended_model(\n",
    "    model,\n",
    "    val_samples,\n",
    "    user_encoder,\n",
    "    item_encoder,\n",
    "    edge_index,\n",
    "    interactions_df,\n",
    "    tfidf_embeddings,\n",
    "    tfidf_vectorizer,\n",
    "    bert_embeddings,\n",
    "    bert4rec_user_embeddings,\n",
    "    news_id_to_idx,\n",
    "    k=10,\n",
    "    alpha=0.4,\n",
    "    beta=0.2,\n",
    "    gamma=0.2,\n",
    "    delta=0.2\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluate the blended model using only the candidate impressions shown to user.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    ndcgs = []\n",
    "\n",
    "    for _, row in val_samples.iterrows():\n",
    "        user_id = row['user_id']\n",
    "        candidate_news_ids = row['candidate_news']\n",
    "        labels = row['labels']\n",
    "\n",
    "        # --- Pass candidate_news_ids correctly ---\n",
    "        predicted_top_news = blended_recommendation(\n",
    "            user_id=user_id,\n",
    "            user_encoder=user_encoder,\n",
    "            item_encoder=item_encoder,\n",
    "            model=model,\n",
    "            edge_index=edge_index,\n",
    "            interactions_df=interactions_df,\n",
    "            tfidf_embeddings=tfidf_embeddings,\n",
    "            tfidf_vectorizer=tfidf_vectorizer,\n",
    "            bert_embeddings=bert_embeddings,\n",
    "            bert4rec_user_embeddings=bert4rec_user_embeddings,\n",
    "            news_id_to_idx=news_id_to_idx,\n",
    "            top_k=len(candidate_news_ids),\n",
    "            candidate_news_ids=candidate_news_ids,  # IMPORTANT!!\n",
    "            alpha=alpha,\n",
    "            beta=beta,\n",
    "            gamma=gamma,\n",
    "            delta=delta\n",
    "        )\n",
    "\n",
    "        # Create binary relevance: 1 if predicted in top news, else 0\n",
    "        predicted_binary = [1 if nid in predicted_top_news else 0 for nid in candidate_news_ids]\n",
    "\n",
    "        if len(predicted_binary) != len(labels):\n",
    "            continue  # skip if mismatch\n",
    "\n",
    "        ndcg = ndcg_score([labels], [predicted_binary], k=k)\n",
    "        ndcgs.append(ndcg)\n",
    "\n",
    "    return sum(ndcgs) / len(ndcgs) if ndcgs else 0.0\n",
    "    \n",
    "# --- Now evaluate ---\n",
    "final_ndcg10 = evaluate_blended_model(\n",
    "    model=model,\n",
    "    val_samples=test_samples,\n",
    "    user_encoder=user_encoder,\n",
    "    item_encoder=item_encoder,\n",
    "    edge_index=edge_index,\n",
    "    interactions_df=interactions_df,\n",
    "    tfidf_embeddings=tfidf_embeddings,\n",
    "    tfidf_vectorizer=tfidf_vectorizer,\n",
    "    bert_embeddings=bert_embeddings,\n",
    "    bert4rec_user_embeddings=bert4rec_user_embeddings,\n",
    "    news_id_to_idx=news_id_to_idx,\n",
    "    k=10\n",
    ")\n",
    "\n",
    "print(f\"nDCG@10 for Blended Model: {final_ndcg10:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
